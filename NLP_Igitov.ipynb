{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Максем\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Максем\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Максем\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from string import punctuation\n",
    "punctuation = list(punctuation)\n",
    "from razdel import tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pymorphy2\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>martin a posted tassos papadopoulos the greek ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man threatens explosion in moscow thursday aug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>klez the virus that won t die already the most...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in adding cream to spaghetti carbonara which ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  label\n",
       "0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0\n",
       "1  martin a posted tassos papadopoulos the greek ...      0\n",
       "2  man threatens explosion in moscow thursday aug...      0\n",
       "3  klez the virus that won t die already the most...      0\n",
       "4   in adding cream to spaghetti carbonara which ...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Максем\\Downloads\\archive (2)\\spam_or_not_spam.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['email'].fillna(method = 'ffill', inplace = True)\n",
    "df['email'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s):\n",
    "   #Очистка от html\n",
    "    soup = BeautifulSoup(s, 'html.parser')\n",
    "    soup.get_text()\n",
    "   #Удаление скрипта\n",
    "    for data in soup(['style', 'script']):\n",
    "      data.decompose()\n",
    "    script_out = ' '.join(soup.stripped_strings)\n",
    "  #Токенизация\n",
    "    tokens = word_tokenize(s)\n",
    "  # Удаляем пунктуацию\n",
    "    tokens_without_punct = [i for i in tokens if i not in punctuation]\n",
    "    low_tokens = [i.lower() for i in tokens_without_punct]\n",
    "  # удаляем стоп-слова из нашего текста\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    words_without_stop = [i for i in low_tokens if i not in stopwords]\n",
    "  # Лемматизация\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    lemms = [lemmatizer.lemmatize(word) for word in words_without_stop]\n",
    "  # Стемминг\n",
    "    ps = PorterStemmer()\n",
    "    stems = [ps.stem(i) for i in lemms]\n",
    "  # Вывод значения в строке\n",
    "    total=''\n",
    "    for el in stems:\n",
    "      total+=el\n",
    "      total+=' '\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalized'] = df['email'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n",
       "      <td>0</td>\n",
       "      <td>date wed number aug number number number numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>martin a posted tassos papadopoulos the greek ...</td>\n",
       "      <td>0</td>\n",
       "      <td>martin post tasso papadopoulo greek sculptor b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man threatens explosion in moscow thursday aug...</td>\n",
       "      <td>0</td>\n",
       "      <td>man threaten explos moscow thursday august num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>klez the virus that won t die already the most...</td>\n",
       "      <td>0</td>\n",
       "      <td>klez viru die alreadi prolif viru ever klez co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in adding cream to spaghetti carbonara which ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ad cream spaghetti carbonara effect pasta make...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  label  \\\n",
       "0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0   \n",
       "1  martin a posted tassos papadopoulos the greek ...      0   \n",
       "2  man threatens explosion in moscow thursday aug...      0   \n",
       "3  klez the virus that won t die already the most...      0   \n",
       "4   in adding cream to spaghetti carbonara which ...      0   \n",
       "\n",
       "                                          normalized  \n",
       "0  date wed number aug number number number numbe...  \n",
       "1  martin post tasso papadopoulo greek sculptor b...  \n",
       "2  man threaten explos moscow thursday august num...  \n",
       "3  klez viru die alreadi prolif viru ever klez co...  \n",
       "4  ad cream spaghetti carbonara effect pasta make...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__</th>\n",
       "      <th>___</th>\n",
       "      <th>____</th>\n",
       "      <th>_____</th>\n",
       "      <th>______</th>\n",
       "      <th>_______</th>\n",
       "      <th>________</th>\n",
       "      <th>_________</th>\n",
       "      <th>__________</th>\n",
       "      <th>______________</th>\n",
       "      <th>...</th>\n",
       "      <th>허락없이</th>\n",
       "      <th>헤어디자이너</th>\n",
       "      <th>현재</th>\n",
       "      <th>호황을</th>\n",
       "      <th>홈쇼핑의</th>\n",
       "      <th>확실한</th>\n",
       "      <th>활황을</th>\n",
       "      <th>훨씬</th>\n",
       "      <th>힘입어</th>\n",
       "      <th>ｉt的技</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25612 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    __  ___  ____  _____  ______  _______  ________  _________  __________  \\\n",
       "0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0         0.0   \n",
       "1  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0         0.0   \n",
       "2  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0         0.0   \n",
       "3  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0         0.0   \n",
       "4  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0         0.0   \n",
       "\n",
       "   ______________  ...  허락없이  헤어디자이너   현재  호황을  홈쇼핑의  확실한  활황을   훨씬  힘입어  ｉt的技  \n",
       "0             0.0  ...   0.0     0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1             0.0  ...   0.0     0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "2             0.0  ...   0.0     0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "3             0.0  ...   0.0     0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "4             0.0  ...   0.0     0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 25612 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['normalized'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__</th>\n",
       "      <th>___</th>\n",
       "      <th>____</th>\n",
       "      <th>_____</th>\n",
       "      <th>______</th>\n",
       "      <th>_______</th>\n",
       "      <th>________</th>\n",
       "      <th>_________</th>\n",
       "      <th>__________</th>\n",
       "      <th>______________</th>\n",
       "      <th>...</th>\n",
       "      <th>허락없이</th>\n",
       "      <th>헤어디자이너</th>\n",
       "      <th>현재</th>\n",
       "      <th>호황을</th>\n",
       "      <th>홈쇼핑의</th>\n",
       "      <th>확실한</th>\n",
       "      <th>활황을</th>\n",
       "      <th>훨씬</th>\n",
       "      <th>힘입어</th>\n",
       "      <th>ｉt的技</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25612 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   __  ___  ____  _____  ______  _______  ________  _________  __________  \\\n",
       "0   0    0     0      0       0        0         0          0           0   \n",
       "1   0    0     0      0       0        0         0          0           0   \n",
       "2   0    0     0      0       0        0         0          0           0   \n",
       "3   0    0     0      0       0        0         0          0           0   \n",
       "4   0    0     0      0       0        0         0          0           0   \n",
       "\n",
       "   ______________  ...  허락없이  헤어디자이너  현재  호황을  홈쇼핑의  확실한  활황을  훨씬  힘입어  ｉt的技  \n",
       "0               0  ...     0       0   0    0     0    0    0   0    0     0  \n",
       "1               0  ...     0       0   0    0     0    0    0   0    0     0  \n",
       "2               0  ...     0       0   0    0     0    0    0   0    0     0  \n",
       "3               0  ...     0       0   0    0     0    0    0   0    0     0  \n",
       "4               0  ...     0       0   0    0     0    0    0   0    0     0  \n",
       "\n",
       "[5 rows x 25612 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_matrix = count_vectorizer.fit_transform(df['normalized'])\n",
    "count_df = pd.DataFrame(data=count_matrix.toarray(), columns=count_vectorizer.get_feature_names_out())\n",
    "count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf_df\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grid_search = GridSearchCV(DecisionTreeClassifier(),\n",
    "                               [{'max_depth': [5, 10, 15],'min_samples_leaf': [1, 2, 4]}],\n",
    "                               cv=5,\n",
    "                               verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START max_depth=5, min_samples_leaf=1.............................\n",
      "[CV 1/5; 1/9] END max_depth=5, min_samples_leaf=1;, score=0.944 total time=   2.8s\n",
      "[CV 2/5; 1/9] START max_depth=5, min_samples_leaf=1.............................\n",
      "[CV 2/5; 1/9] END max_depth=5, min_samples_leaf=1;, score=0.944 total time=   2.9s\n",
      "[CV 3/5; 1/9] START max_depth=5, min_samples_leaf=1.............................\n",
      "[CV 3/5; 1/9] END max_depth=5, min_samples_leaf=1;, score=0.958 total time=   3.1s\n",
      "[CV 4/5; 1/9] START max_depth=5, min_samples_leaf=1.............................\n",
      "[CV 4/5; 1/9] END max_depth=5, min_samples_leaf=1;, score=0.971 total time=   2.9s\n",
      "[CV 5/5; 1/9] START max_depth=5, min_samples_leaf=1.............................\n",
      "[CV 5/5; 1/9] END max_depth=5, min_samples_leaf=1;, score=0.958 total time=   2.4s\n",
      "[CV 1/5; 2/9] START max_depth=5, min_samples_leaf=2.............................\n",
      "[CV 1/5; 2/9] END max_depth=5, min_samples_leaf=2;, score=0.938 total time=   3.1s\n",
      "[CV 2/5; 2/9] START max_depth=5, min_samples_leaf=2.............................\n",
      "[CV 2/5; 2/9] END max_depth=5, min_samples_leaf=2;, score=0.944 total time=   2.9s\n",
      "[CV 3/5; 2/9] START max_depth=5, min_samples_leaf=2.............................\n",
      "[CV 3/5; 2/9] END max_depth=5, min_samples_leaf=2;, score=0.956 total time=   2.7s\n",
      "[CV 4/5; 2/9] START max_depth=5, min_samples_leaf=2.............................\n",
      "[CV 4/5; 2/9] END max_depth=5, min_samples_leaf=2;, score=0.969 total time=   2.7s\n",
      "[CV 5/5; 2/9] START max_depth=5, min_samples_leaf=2.............................\n",
      "[CV 5/5; 2/9] END max_depth=5, min_samples_leaf=2;, score=0.958 total time=   2.4s\n",
      "[CV 1/5; 3/9] START max_depth=5, min_samples_leaf=4.............................\n",
      "[CV 1/5; 3/9] END max_depth=5, min_samples_leaf=4;, score=0.948 total time=   3.1s\n",
      "[CV 2/5; 3/9] START max_depth=5, min_samples_leaf=4.............................\n",
      "[CV 2/5; 3/9] END max_depth=5, min_samples_leaf=4;, score=0.942 total time=   2.9s\n",
      "[CV 3/5; 3/9] START max_depth=5, min_samples_leaf=4.............................\n",
      "[CV 3/5; 3/9] END max_depth=5, min_samples_leaf=4;, score=0.954 total time=   2.7s\n",
      "[CV 4/5; 3/9] START max_depth=5, min_samples_leaf=4.............................\n",
      "[CV 4/5; 3/9] END max_depth=5, min_samples_leaf=4;, score=0.971 total time=   2.9s\n",
      "[CV 5/5; 3/9] START max_depth=5, min_samples_leaf=4.............................\n",
      "[CV 5/5; 3/9] END max_depth=5, min_samples_leaf=4;, score=0.958 total time=   2.6s\n",
      "[CV 1/5; 4/9] START max_depth=10, min_samples_leaf=1............................\n",
      "[CV 1/5; 4/9] END max_depth=10, min_samples_leaf=1;, score=0.935 total time=   4.5s\n",
      "[CV 2/5; 4/9] START max_depth=10, min_samples_leaf=1............................\n",
      "[CV 2/5; 4/9] END max_depth=10, min_samples_leaf=1;, score=0.946 total time=   4.3s\n",
      "[CV 3/5; 4/9] START max_depth=10, min_samples_leaf=1............................\n",
      "[CV 3/5; 4/9] END max_depth=10, min_samples_leaf=1;, score=0.965 total time=   4.4s\n",
      "[CV 4/5; 4/9] START max_depth=10, min_samples_leaf=1............................\n",
      "[CV 4/5; 4/9] END max_depth=10, min_samples_leaf=1;, score=0.971 total time=   4.2s\n",
      "[CV 5/5; 4/9] START max_depth=10, min_samples_leaf=1............................\n",
      "[CV 5/5; 4/9] END max_depth=10, min_samples_leaf=1;, score=0.969 total time=   3.8s\n",
      "[CV 1/5; 5/9] START max_depth=10, min_samples_leaf=2............................\n",
      "[CV 1/5; 5/9] END max_depth=10, min_samples_leaf=2;, score=0.944 total time=   4.3s\n",
      "[CV 2/5; 5/9] START max_depth=10, min_samples_leaf=2............................\n",
      "[CV 2/5; 5/9] END max_depth=10, min_samples_leaf=2;, score=0.942 total time=   4.3s\n",
      "[CV 3/5; 5/9] START max_depth=10, min_samples_leaf=2............................\n",
      "[CV 3/5; 5/9] END max_depth=10, min_samples_leaf=2;, score=0.965 total time=   4.5s\n",
      "[CV 4/5; 5/9] START max_depth=10, min_samples_leaf=2............................\n",
      "[CV 4/5; 5/9] END max_depth=10, min_samples_leaf=2;, score=0.969 total time=   4.3s\n",
      "[CV 5/5; 5/9] START max_depth=10, min_samples_leaf=2............................\n",
      "[CV 5/5; 5/9] END max_depth=10, min_samples_leaf=2;, score=0.967 total time=   3.8s\n",
      "[CV 1/5; 6/9] START max_depth=10, min_samples_leaf=4............................\n",
      "[CV 1/5; 6/9] END max_depth=10, min_samples_leaf=4;, score=0.950 total time=   4.3s\n",
      "[CV 2/5; 6/9] START max_depth=10, min_samples_leaf=4............................\n",
      "[CV 2/5; 6/9] END max_depth=10, min_samples_leaf=4;, score=0.944 total time=   4.3s\n",
      "[CV 3/5; 6/9] START max_depth=10, min_samples_leaf=4............................\n",
      "[CV 3/5; 6/9] END max_depth=10, min_samples_leaf=4;, score=0.958 total time=   4.4s\n",
      "[CV 4/5; 6/9] START max_depth=10, min_samples_leaf=4............................\n",
      "[CV 4/5; 6/9] END max_depth=10, min_samples_leaf=4;, score=0.965 total time=   4.3s\n",
      "[CV 5/5; 6/9] START max_depth=10, min_samples_leaf=4............................\n",
      "[CV 5/5; 6/9] END max_depth=10, min_samples_leaf=4;, score=0.969 total time=   3.7s\n",
      "[CV 1/5; 7/9] START max_depth=15, min_samples_leaf=1............................\n",
      "[CV 1/5; 7/9] END max_depth=15, min_samples_leaf=1;, score=0.933 total time=   6.0s\n",
      "[CV 2/5; 7/9] START max_depth=15, min_samples_leaf=1............................\n",
      "[CV 2/5; 7/9] END max_depth=15, min_samples_leaf=1;, score=0.954 total time=   5.7s\n",
      "[CV 3/5; 7/9] START max_depth=15, min_samples_leaf=1............................\n",
      "[CV 3/5; 7/9] END max_depth=15, min_samples_leaf=1;, score=0.969 total time=   5.9s\n",
      "[CV 4/5; 7/9] START max_depth=15, min_samples_leaf=1............................\n",
      "[CV 4/5; 7/9] END max_depth=15, min_samples_leaf=1;, score=0.971 total time=   5.7s\n",
      "[CV 5/5; 7/9] START max_depth=15, min_samples_leaf=1............................\n",
      "[CV 5/5; 7/9] END max_depth=15, min_samples_leaf=1;, score=0.971 total time=   4.9s\n",
      "[CV 1/5; 8/9] START max_depth=15, min_samples_leaf=2............................\n",
      "[CV 1/5; 8/9] END max_depth=15, min_samples_leaf=2;, score=0.933 total time=   6.1s\n",
      "[CV 2/5; 8/9] START max_depth=15, min_samples_leaf=2............................\n",
      "[CV 2/5; 8/9] END max_depth=15, min_samples_leaf=2;, score=0.954 total time=   5.5s\n",
      "[CV 3/5; 8/9] START max_depth=15, min_samples_leaf=2............................\n",
      "[CV 3/5; 8/9] END max_depth=15, min_samples_leaf=2;, score=0.963 total time=   6.1s\n",
      "[CV 4/5; 8/9] START max_depth=15, min_samples_leaf=2............................\n",
      "[CV 4/5; 8/9] END max_depth=15, min_samples_leaf=2;, score=0.973 total time=   5.7s\n",
      "[CV 5/5; 8/9] START max_depth=15, min_samples_leaf=2............................\n",
      "[CV 5/5; 8/9] END max_depth=15, min_samples_leaf=2;, score=0.973 total time=   5.0s\n",
      "[CV 1/5; 9/9] START max_depth=15, min_samples_leaf=4............................\n",
      "[CV 1/5; 9/9] END max_depth=15, min_samples_leaf=4;, score=0.954 total time=   5.8s\n",
      "[CV 2/5; 9/9] START max_depth=15, min_samples_leaf=4............................\n",
      "[CV 2/5; 9/9] END max_depth=15, min_samples_leaf=4;, score=0.948 total time=   5.7s\n",
      "[CV 3/5; 9/9] START max_depth=15, min_samples_leaf=4............................\n",
      "[CV 3/5; 9/9] END max_depth=15, min_samples_leaf=4;, score=0.960 total time=   6.0s\n",
      "[CV 4/5; 9/9] START max_depth=15, min_samples_leaf=4............................\n",
      "[CV 4/5; 9/9] END max_depth=15, min_samples_leaf=4;, score=0.969 total time=   5.7s\n",
      "[CV 5/5; 9/9] START max_depth=15, min_samples_leaf=4............................\n",
      "[CV 5/5; 9/9] END max_depth=15, min_samples_leaf=4;, score=0.965 total time=   5.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid=[{'max_depth': [5, 10, 15],\n",
       "                          'min_samples_leaf': [1, 2, 4]}],\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 15, 'min_samples_leaf': 1}\n",
      "0.9595833333333333\n",
      "DecisionTreeClassifier(max_depth=15)\n"
     ]
    }
   ],
   "source": [
    "print(t_grid_search.best_params_)\n",
    "print(t_grid_search.best_score_)\n",
    "print(t_grid_search.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = count_df\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_train, C_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_grid_search = GridSearchCV(DecisionTreeClassifier(),\n",
    "                               [{'max_depth': [5, 10, 15],'min_samples_leaf': [1, 2, 4]}],\n",
    "                               cv=5,\n",
    "                               verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START max_depth=5, min_samples_leaf=1.............................\n",
      "[CV 1/5; 1/9] END max_depth=5, min_samples_leaf=1;, score=0.946 total time=   2.8s\n",
      "[CV 2/5; 1/9] START max_depth=5, min_samples_leaf=1.............................\n",
      "[CV 2/5; 1/9] END max_depth=5, min_samples_leaf=1;, score=0.946 total time=   2.7s\n",
      "[CV 3/5; 1/9] START max_depth=5, min_samples_leaf=1.............................\n",
      "[CV 3/5; 1/9] END max_depth=5, min_samples_leaf=1;, score=0.958 total time=   2.8s\n",
      "[CV 4/5; 1/9] START max_depth=5, min_samples_leaf=1.............................\n",
      "[CV 4/5; 1/9] END max_depth=5, min_samples_leaf=1;, score=0.971 total time=   2.7s\n",
      "[CV 5/5; 1/9] START max_depth=5, min_samples_leaf=1.............................\n",
      "[CV 5/5; 1/9] END max_depth=5, min_samples_leaf=1;, score=0.958 total time=   2.4s\n",
      "[CV 1/5; 2/9] START max_depth=5, min_samples_leaf=2.............................\n",
      "[CV 1/5; 2/9] END max_depth=5, min_samples_leaf=2;, score=0.931 total time=   2.7s\n",
      "[CV 2/5; 2/9] START max_depth=5, min_samples_leaf=2.............................\n",
      "[CV 2/5; 2/9] END max_depth=5, min_samples_leaf=2;, score=0.946 total time=   2.8s\n",
      "[CV 3/5; 2/9] START max_depth=5, min_samples_leaf=2.............................\n",
      "[CV 3/5; 2/9] END max_depth=5, min_samples_leaf=2;, score=0.956 total time=   2.9s\n",
      "[CV 4/5; 2/9] START max_depth=5, min_samples_leaf=2.............................\n",
      "[CV 4/5; 2/9] END max_depth=5, min_samples_leaf=2;, score=0.971 total time=   2.8s\n",
      "[CV 5/5; 2/9] START max_depth=5, min_samples_leaf=2.............................\n",
      "[CV 5/5; 2/9] END max_depth=5, min_samples_leaf=2;, score=0.958 total time=   2.5s\n",
      "[CV 1/5; 3/9] START max_depth=5, min_samples_leaf=4.............................\n",
      "[CV 1/5; 3/9] END max_depth=5, min_samples_leaf=4;, score=0.944 total time=   3.0s\n",
      "[CV 2/5; 3/9] START max_depth=5, min_samples_leaf=4.............................\n",
      "[CV 2/5; 3/9] END max_depth=5, min_samples_leaf=4;, score=0.946 total time=   3.3s\n",
      "[CV 3/5; 3/9] START max_depth=5, min_samples_leaf=4.............................\n",
      "[CV 3/5; 3/9] END max_depth=5, min_samples_leaf=4;, score=0.954 total time=   2.9s\n",
      "[CV 4/5; 3/9] START max_depth=5, min_samples_leaf=4.............................\n",
      "[CV 4/5; 3/9] END max_depth=5, min_samples_leaf=4;, score=0.971 total time=   2.7s\n",
      "[CV 5/5; 3/9] START max_depth=5, min_samples_leaf=4.............................\n",
      "[CV 5/5; 3/9] END max_depth=5, min_samples_leaf=4;, score=0.958 total time=   2.4s\n",
      "[CV 1/5; 4/9] START max_depth=10, min_samples_leaf=1............................\n",
      "[CV 1/5; 4/9] END max_depth=10, min_samples_leaf=1;, score=0.940 total time=   4.9s\n",
      "[CV 2/5; 4/9] START max_depth=10, min_samples_leaf=1............................\n",
      "[CV 2/5; 4/9] END max_depth=10, min_samples_leaf=1;, score=0.944 total time=   4.6s\n",
      "[CV 3/5; 4/9] START max_depth=10, min_samples_leaf=1............................\n",
      "[CV 3/5; 4/9] END max_depth=10, min_samples_leaf=1;, score=0.963 total time=   4.9s\n",
      "[CV 4/5; 4/9] START max_depth=10, min_samples_leaf=1............................\n",
      "[CV 4/5; 4/9] END max_depth=10, min_samples_leaf=1;, score=0.971 total time=   4.4s\n",
      "[CV 5/5; 4/9] START max_depth=10, min_samples_leaf=1............................\n",
      "[CV 5/5; 4/9] END max_depth=10, min_samples_leaf=1;, score=0.971 total time=   3.9s\n",
      "[CV 1/5; 5/9] START max_depth=10, min_samples_leaf=2............................\n",
      "[CV 1/5; 5/9] END max_depth=10, min_samples_leaf=2;, score=0.929 total time=   4.5s\n",
      "[CV 2/5; 5/9] START max_depth=10, min_samples_leaf=2............................\n",
      "[CV 2/5; 5/9] END max_depth=10, min_samples_leaf=2;, score=0.948 total time=   4.2s\n",
      "[CV 3/5; 5/9] START max_depth=10, min_samples_leaf=2............................\n",
      "[CV 3/5; 5/9] END max_depth=10, min_samples_leaf=2;, score=0.965 total time=   4.5s\n",
      "[CV 4/5; 5/9] START max_depth=10, min_samples_leaf=2............................\n",
      "[CV 4/5; 5/9] END max_depth=10, min_samples_leaf=2;, score=0.975 total time=   4.4s\n",
      "[CV 5/5; 5/9] START max_depth=10, min_samples_leaf=2............................\n",
      "[CV 5/5; 5/9] END max_depth=10, min_samples_leaf=2;, score=0.969 total time=   3.7s\n",
      "[CV 1/5; 6/9] START max_depth=10, min_samples_leaf=4............................\n",
      "[CV 1/5; 6/9] END max_depth=10, min_samples_leaf=4;, score=0.946 total time=   4.6s\n",
      "[CV 2/5; 6/9] START max_depth=10, min_samples_leaf=4............................\n",
      "[CV 2/5; 6/9] END max_depth=10, min_samples_leaf=4;, score=0.944 total time=   4.2s\n",
      "[CV 3/5; 6/9] START max_depth=10, min_samples_leaf=4............................\n",
      "[CV 3/5; 6/9] END max_depth=10, min_samples_leaf=4;, score=0.960 total time=   4.5s\n",
      "[CV 4/5; 6/9] START max_depth=10, min_samples_leaf=4............................\n",
      "[CV 4/5; 6/9] END max_depth=10, min_samples_leaf=4;, score=0.967 total time=   4.2s\n",
      "[CV 5/5; 6/9] START max_depth=10, min_samples_leaf=4............................\n",
      "[CV 5/5; 6/9] END max_depth=10, min_samples_leaf=4;, score=0.965 total time=   3.9s\n",
      "[CV 1/5; 7/9] START max_depth=15, min_samples_leaf=1............................\n",
      "[CV 1/5; 7/9] END max_depth=15, min_samples_leaf=1;, score=0.935 total time=   5.5s\n",
      "[CV 2/5; 7/9] START max_depth=15, min_samples_leaf=1............................\n",
      "[CV 2/5; 7/9] END max_depth=15, min_samples_leaf=1;, score=0.950 total time=   5.5s\n",
      "[CV 3/5; 7/9] START max_depth=15, min_samples_leaf=1............................\n",
      "[CV 3/5; 7/9] END max_depth=15, min_samples_leaf=1;, score=0.965 total time=   5.8s\n",
      "[CV 4/5; 7/9] START max_depth=15, min_samples_leaf=1............................\n",
      "[CV 4/5; 7/9] END max_depth=15, min_samples_leaf=1;, score=0.975 total time=   5.5s\n",
      "[CV 5/5; 7/9] START max_depth=15, min_samples_leaf=1............................\n",
      "[CV 5/5; 7/9] END max_depth=15, min_samples_leaf=1;, score=0.971 total time=   5.0s\n",
      "[CV 1/5; 8/9] START max_depth=15, min_samples_leaf=2............................\n",
      "[CV 1/5; 8/9] END max_depth=15, min_samples_leaf=2;, score=0.933 total time=   5.7s\n",
      "[CV 2/5; 8/9] START max_depth=15, min_samples_leaf=2............................\n",
      "[CV 2/5; 8/9] END max_depth=15, min_samples_leaf=2;, score=0.954 total time=   5.6s\n",
      "[CV 3/5; 8/9] START max_depth=15, min_samples_leaf=2............................\n",
      "[CV 3/5; 8/9] END max_depth=15, min_samples_leaf=2;, score=0.958 total time=   5.9s\n",
      "[CV 4/5; 8/9] START max_depth=15, min_samples_leaf=2............................\n",
      "[CV 4/5; 8/9] END max_depth=15, min_samples_leaf=2;, score=0.977 total time=   5.6s\n",
      "[CV 5/5; 8/9] START max_depth=15, min_samples_leaf=2............................\n",
      "[CV 5/5; 8/9] END max_depth=15, min_samples_leaf=2;, score=0.969 total time=   5.0s\n",
      "[CV 1/5; 9/9] START max_depth=15, min_samples_leaf=4............................\n",
      "[CV 1/5; 9/9] END max_depth=15, min_samples_leaf=4;, score=0.963 total time=   5.7s\n",
      "[CV 2/5; 9/9] START max_depth=15, min_samples_leaf=4............................\n",
      "[CV 2/5; 9/9] END max_depth=15, min_samples_leaf=4;, score=0.946 total time=   5.4s\n",
      "[CV 3/5; 9/9] START max_depth=15, min_samples_leaf=4............................\n",
      "[CV 3/5; 9/9] END max_depth=15, min_samples_leaf=4;, score=0.946 total time=   5.8s\n",
      "[CV 4/5; 9/9] START max_depth=15, min_samples_leaf=4............................\n",
      "[CV 4/5; 9/9] END max_depth=15, min_samples_leaf=4;, score=0.967 total time=   5.5s\n",
      "[CV 5/5; 9/9] START max_depth=15, min_samples_leaf=4............................\n",
      "[CV 5/5; 9/9] END max_depth=15, min_samples_leaf=4;, score=0.963 total time=   4.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid=[{'max_depth': [5, 10, 15],\n",
       "                          'min_samples_leaf': [1, 2, 4]}],\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec_grid_search.fit(C_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 15, 'min_samples_leaf': 1}\n",
      "0.9591666666666667\n",
      "DecisionTreeClassifier(max_depth=15)\n"
     ]
    }
   ],
   "source": [
    "print(cvec_grid_search.best_params_)\n",
    "print(cvec_grid_search.best_score_)\n",
    "print(cvec_grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате сравнения лучшего скора кросс - валидации для дерева решений, точность выше у векторизации текста при помощи TF - IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_grid_search = GridSearchCV(LogisticRegression(),\n",
    "                               [{'penalty': ['l1', 'l2', 'elasticnet'], 'C': [0.1, 1, 10, 100]  }],\n",
    "                               cv=5,\n",
    "                               verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5; 1/12] START C=0.1, penalty=l1..........................................\n",
      "[CV 1/5; 1/12] END .............C=0.1, penalty=l1;, score=nan total time=   0.2s\n",
      "[CV 2/5; 1/12] START C=0.1, penalty=l1..........................................\n",
      "[CV 2/5; 1/12] END .............C=0.1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/5; 1/12] START C=0.1, penalty=l1..........................................\n",
      "[CV 3/5; 1/12] END .............C=0.1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 4/5; 1/12] START C=0.1, penalty=l1..........................................\n",
      "[CV 4/5; 1/12] END .............C=0.1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 5/5; 1/12] START C=0.1, penalty=l1..........................................\n",
      "[CV 5/5; 1/12] END .............C=0.1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/5; 2/12] START C=0.1, penalty=l2..........................................\n",
      "[CV 1/5; 2/12] END ...........C=0.1, penalty=l2;, score=0.846 total time=   1.3s\n",
      "[CV 2/5; 2/12] START C=0.1, penalty=l2..........................................\n",
      "[CV 2/5; 2/12] END ...........C=0.1, penalty=l2;, score=0.838 total time=   1.4s\n",
      "[CV 3/5; 2/12] START C=0.1, penalty=l2..........................................\n",
      "[CV 3/5; 2/12] END ...........C=0.1, penalty=l2;, score=0.848 total time=   1.3s\n",
      "[CV 4/5; 2/12] START C=0.1, penalty=l2..........................................\n",
      "[CV 4/5; 2/12] END ...........C=0.1, penalty=l2;, score=0.840 total time=   1.6s\n",
      "[CV 5/5; 2/12] START C=0.1, penalty=l2..........................................\n",
      "[CV 5/5; 2/12] END ...........C=0.1, penalty=l2;, score=0.840 total time=   1.3s\n",
      "[CV 1/5; 3/12] START C=0.1, penalty=elasticnet..................................\n",
      "[CV 1/5; 3/12] END .....C=0.1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/5; 3/12] START C=0.1, penalty=elasticnet..................................\n",
      "[CV 2/5; 3/12] END .....C=0.1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/5; 3/12] START C=0.1, penalty=elasticnet..................................\n",
      "[CV 3/5; 3/12] END .....C=0.1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 4/5; 3/12] START C=0.1, penalty=elasticnet..................................\n",
      "[CV 4/5; 3/12] END .....C=0.1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 5/5; 3/12] START C=0.1, penalty=elasticnet..................................\n",
      "[CV 5/5; 3/12] END .....C=0.1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/5; 4/12] START C=1, penalty=l1............................................\n",
      "[CV 1/5; 4/12] END ...............C=1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/5; 4/12] START C=1, penalty=l1............................................\n",
      "[CV 2/5; 4/12] END ...............C=1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/5; 4/12] START C=1, penalty=l1............................................\n",
      "[CV 3/5; 4/12] END ...............C=1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 4/5; 4/12] START C=1, penalty=l1............................................\n",
      "[CV 4/5; 4/12] END ...............C=1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 5/5; 4/12] START C=1, penalty=l1............................................\n",
      "[CV 5/5; 4/12] END ...............C=1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/5; 5/12] START C=1, penalty=l2............................................\n",
      "[CV 1/5; 5/12] END .............C=1, penalty=l2;, score=0.944 total time=   2.1s\n",
      "[CV 2/5; 5/12] START C=1, penalty=l2............................................\n",
      "[CV 2/5; 5/12] END .............C=1, penalty=l2;, score=0.948 total time=   2.1s\n",
      "[CV 3/5; 5/12] START C=1, penalty=l2............................................\n",
      "[CV 3/5; 5/12] END .............C=1, penalty=l2;, score=0.956 total time=   2.1s\n",
      "[CV 4/5; 5/12] START C=1, penalty=l2............................................\n",
      "[CV 4/5; 5/12] END .............C=1, penalty=l2;, score=0.952 total time=   2.1s\n",
      "[CV 5/5; 5/12] START C=1, penalty=l2............................................\n",
      "[CV 5/5; 5/12] END .............C=1, penalty=l2;, score=0.956 total time=   1.8s\n",
      "[CV 1/5; 6/12] START C=1, penalty=elasticnet....................................\n",
      "[CV 1/5; 6/12] END .......C=1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/5; 6/12] START C=1, penalty=elasticnet....................................\n",
      "[CV 2/5; 6/12] END .......C=1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/5; 6/12] START C=1, penalty=elasticnet....................................\n",
      "[CV 3/5; 6/12] END .......C=1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 4/5; 6/12] START C=1, penalty=elasticnet....................................\n",
      "[CV 4/5; 6/12] END .......C=1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 5/5; 6/12] START C=1, penalty=elasticnet....................................\n",
      "[CV 5/5; 6/12] END .......C=1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/5; 7/12] START C=10, penalty=l1...........................................\n",
      "[CV 1/5; 7/12] END ..............C=10, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/5; 7/12] START C=10, penalty=l1...........................................\n",
      "[CV 2/5; 7/12] END ..............C=10, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/5; 7/12] START C=10, penalty=l1...........................................\n",
      "[CV 3/5; 7/12] END ..............C=10, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 4/5; 7/12] START C=10, penalty=l1...........................................\n",
      "[CV 4/5; 7/12] END ..............C=10, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 5/5; 7/12] START C=10, penalty=l1...........................................\n",
      "[CV 5/5; 7/12] END ..............C=10, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/5; 8/12] START C=10, penalty=l2...........................................\n",
      "[CV 1/5; 8/12] END ............C=10, penalty=l2;, score=0.975 total time=   3.4s\n",
      "[CV 2/5; 8/12] START C=10, penalty=l2...........................................\n",
      "[CV 2/5; 8/12] END ............C=10, penalty=l2;, score=0.983 total time=   3.4s\n",
      "[CV 3/5; 8/12] START C=10, penalty=l2...........................................\n",
      "[CV 3/5; 8/12] END ............C=10, penalty=l2;, score=0.988 total time=   3.1s\n",
      "[CV 4/5; 8/12] START C=10, penalty=l2...........................................\n",
      "[CV 4/5; 8/12] END ............C=10, penalty=l2;, score=0.977 total time=   3.4s\n",
      "[CV 5/5; 8/12] START C=10, penalty=l2...........................................\n",
      "[CV 5/5; 8/12] END ............C=10, penalty=l2;, score=0.994 total time=   3.2s\n",
      "[CV 1/5; 9/12] START C=10, penalty=elasticnet...................................\n",
      "[CV 1/5; 9/12] END ......C=10, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/5; 9/12] START C=10, penalty=elasticnet...................................\n",
      "[CV 2/5; 9/12] END ......C=10, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/5; 9/12] START C=10, penalty=elasticnet...................................\n",
      "[CV 3/5; 9/12] END ......C=10, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 4/5; 9/12] START C=10, penalty=elasticnet...................................\n",
      "[CV 4/5; 9/12] END ......C=10, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 5/5; 9/12] START C=10, penalty=elasticnet...................................\n",
      "[CV 5/5; 9/12] END ......C=10, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/5; 10/12] START C=100, penalty=l1.........................................\n",
      "[CV 1/5; 10/12] END ............C=100, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/5; 10/12] START C=100, penalty=l1.........................................\n",
      "[CV 2/5; 10/12] END ............C=100, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/5; 10/12] START C=100, penalty=l1.........................................\n",
      "[CV 3/5; 10/12] END ............C=100, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 4/5; 10/12] START C=100, penalty=l1.........................................\n",
      "[CV 4/5; 10/12] END ............C=100, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 5/5; 10/12] START C=100, penalty=l1.........................................\n",
      "[CV 5/5; 10/12] END ............C=100, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/5; 11/12] START C=100, penalty=l2.........................................\n",
      "[CV 1/5; 11/12] END ..........C=100, penalty=l2;, score=0.977 total time=   3.4s\n",
      "[CV 2/5; 11/12] START C=100, penalty=l2.........................................\n",
      "[CV 2/5; 11/12] END ..........C=100, penalty=l2;, score=0.990 total time=   4.5s\n",
      "[CV 3/5; 11/12] START C=100, penalty=l2.........................................\n",
      "[CV 3/5; 11/12] END ..........C=100, penalty=l2;, score=0.988 total time=   3.6s\n",
      "[CV 4/5; 11/12] START C=100, penalty=l2.........................................\n",
      "[CV 4/5; 11/12] END ..........C=100, penalty=l2;, score=0.985 total time=   4.5s\n",
      "[CV 5/5; 11/12] START C=100, penalty=l2.........................................\n",
      "[CV 5/5; 11/12] END ..........C=100, penalty=l2;, score=0.996 total time=   4.1s\n",
      "[CV 1/5; 12/12] START C=100, penalty=elasticnet.................................\n",
      "[CV 1/5; 12/12] END ....C=100, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/5; 12/12] START C=100, penalty=elasticnet.................................\n",
      "[CV 2/5; 12/12] END ....C=100, penalty=elasticnet;, score=nan total time=   0.2s\n",
      "[CV 3/5; 12/12] START C=100, penalty=elasticnet.................................\n",
      "[CV 3/5; 12/12] END ....C=100, penalty=elasticnet;, score=nan total time=   0.2s\n",
      "[CV 4/5; 12/12] START C=100, penalty=elasticnet.................................\n",
      "[CV 4/5; 12/12] END ....C=100, penalty=elasticnet;, score=nan total time=   0.2s\n",
      "[CV 5/5; 12/12] START C=100, penalty=elasticnet.................................\n",
      "[CV 5/5; 12/12] END ....C=100, penalty=elasticnet;, score=nan total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.84208333        nan        nan 0.95125           nan\n",
      "        nan 0.98333333        nan        nan 0.98708333        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid=[{'C': [0.1, 1, 10, 100],\n",
       "                          'penalty': ['l1', 'l2', 'elasticnet']}],\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'penalty': 'l2'}\n",
      "0.9870833333333333\n",
      "LogisticRegression(C=100)\n"
     ]
    }
   ],
   "source": [
    "print(l_grid_search.best_params_)\n",
    "print(l_grid_search.best_score_)\n",
    "print(l_grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = count_df\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_train, C_test, y_train, y_test = train_test_split(C, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvec_grid_search = GridSearchCV(LogisticRegression(),\n",
    "                               [{'penalty': ['l1', 'l2', 'elasticnet'], 'C': [0.1, 1, 10, 100]  }],\n",
    "                               cv=5,\n",
    "                               verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5; 1/12] START C=0.1, penalty=l1..........................................\n",
      "[CV 1/5; 1/12] END .............C=0.1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/5; 1/12] START C=0.1, penalty=l1..........................................\n",
      "[CV 2/5; 1/12] END .............C=0.1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/5; 1/12] START C=0.1, penalty=l1..........................................\n",
      "[CV 3/5; 1/12] END .............C=0.1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 4/5; 1/12] START C=0.1, penalty=l1..........................................\n",
      "[CV 4/5; 1/12] END .............C=0.1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 5/5; 1/12] START C=0.1, penalty=l1..........................................\n",
      "[CV 5/5; 1/12] END .............C=0.1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/5; 2/12] START C=0.1, penalty=l2..........................................\n",
      "[CV 1/5; 2/12] END ...........C=0.1, penalty=l2;, score=0.969 total time=   3.1s\n",
      "[CV 2/5; 2/12] START C=0.1, penalty=l2..........................................\n",
      "[CV 2/5; 2/12] END ...........C=0.1, penalty=l2;, score=0.979 total time=   4.1s\n",
      "[CV 3/5; 2/12] START C=0.1, penalty=l2..........................................\n",
      "[CV 3/5; 2/12] END ...........C=0.1, penalty=l2;, score=0.990 total time=   3.3s\n",
      "[CV 4/5; 2/12] START C=0.1, penalty=l2..........................................\n",
      "[CV 4/5; 2/12] END ...........C=0.1, penalty=l2;, score=0.977 total time=   3.6s\n",
      "[CV 5/5; 2/12] START C=0.1, penalty=l2..........................................\n",
      "[CV 5/5; 2/12] END ...........C=0.1, penalty=l2;, score=0.985 total time=   3.7s\n",
      "[CV 1/5; 3/12] START C=0.1, penalty=elasticnet..................................\n",
      "[CV 1/5; 3/12] END .....C=0.1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/5; 3/12] START C=0.1, penalty=elasticnet..................................\n",
      "[CV 2/5; 3/12] END .....C=0.1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/5; 3/12] START C=0.1, penalty=elasticnet..................................\n",
      "[CV 3/5; 3/12] END .....C=0.1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 4/5; 3/12] START C=0.1, penalty=elasticnet..................................\n",
      "[CV 4/5; 3/12] END .....C=0.1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 5/5; 3/12] START C=0.1, penalty=elasticnet..................................\n",
      "[CV 5/5; 3/12] END .....C=0.1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/5; 4/12] START C=1, penalty=l1............................................\n",
      "[CV 1/5; 4/12] END ...............C=1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/5; 4/12] START C=1, penalty=l1............................................\n",
      "[CV 2/5; 4/12] END ...............C=1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/5; 4/12] START C=1, penalty=l1............................................\n",
      "[CV 3/5; 4/12] END ...............C=1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 4/5; 4/12] START C=1, penalty=l1............................................\n",
      "[CV 4/5; 4/12] END ...............C=1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 5/5; 4/12] START C=1, penalty=l1............................................\n",
      "[CV 5/5; 4/12] END ...............C=1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/5; 5/12] START C=1, penalty=l2............................................\n",
      "[CV 1/5; 5/12] END .............C=1, penalty=l2;, score=0.981 total time=   3.9s\n",
      "[CV 2/5; 5/12] START C=1, penalty=l2............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/12] END .............C=1, penalty=l2;, score=0.990 total time=   5.4s\n",
      "[CV 3/5; 5/12] START C=1, penalty=l2............................................\n",
      "[CV 3/5; 5/12] END .............C=1, penalty=l2;, score=0.992 total time=   5.2s\n",
      "[CV 4/5; 5/12] START C=1, penalty=l2............................................\n",
      "[CV 4/5; 5/12] END .............C=1, penalty=l2;, score=0.983 total time=   5.3s\n",
      "[CV 5/5; 5/12] START C=1, penalty=l2............................................\n",
      "[CV 5/5; 5/12] END .............C=1, penalty=l2;, score=0.994 total time=   4.8s\n",
      "[CV 1/5; 6/12] START C=1, penalty=elasticnet....................................\n",
      "[CV 1/5; 6/12] END .......C=1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/5; 6/12] START C=1, penalty=elasticnet....................................\n",
      "[CV 2/5; 6/12] END .......C=1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/5; 6/12] START C=1, penalty=elasticnet....................................\n",
      "[CV 3/5; 6/12] END .......C=1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 4/5; 6/12] START C=1, penalty=elasticnet....................................\n",
      "[CV 4/5; 6/12] END .......C=1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 5/5; 6/12] START C=1, penalty=elasticnet....................................\n",
      "[CV 5/5; 6/12] END .......C=1, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/5; 7/12] START C=10, penalty=l1...........................................\n",
      "[CV 1/5; 7/12] END ..............C=10, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/5; 7/12] START C=10, penalty=l1...........................................\n",
      "[CV 2/5; 7/12] END ..............C=10, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/5; 7/12] START C=10, penalty=l1...........................................\n",
      "[CV 3/5; 7/12] END ..............C=10, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 4/5; 7/12] START C=10, penalty=l1...........................................\n",
      "[CV 4/5; 7/12] END ..............C=10, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 5/5; 7/12] START C=10, penalty=l1...........................................\n",
      "[CV 5/5; 7/12] END ..............C=10, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/5; 8/12] START C=10, penalty=l2...........................................\n",
      "[CV 1/5; 8/12] END ............C=10, penalty=l2;, score=0.983 total time=   5.3s\n",
      "[CV 2/5; 8/12] START C=10, penalty=l2...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 8/12] END ............C=10, penalty=l2;, score=0.985 total time=   6.2s\n",
      "[CV 3/5; 8/12] START C=10, penalty=l2...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/12] END ............C=10, penalty=l2;, score=0.985 total time=   5.6s\n",
      "[CV 4/5; 8/12] START C=10, penalty=l2...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 8/12] END ............C=10, penalty=l2;, score=0.988 total time=   5.8s\n",
      "[CV 5/5; 8/12] START C=10, penalty=l2...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 8/12] END ............C=10, penalty=l2;, score=0.990 total time=   5.8s\n",
      "[CV 1/5; 9/12] START C=10, penalty=elasticnet...................................\n",
      "[CV 1/5; 9/12] END ......C=10, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/5; 9/12] START C=10, penalty=elasticnet...................................\n",
      "[CV 2/5; 9/12] END ......C=10, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/5; 9/12] START C=10, penalty=elasticnet...................................\n",
      "[CV 3/5; 9/12] END ......C=10, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 4/5; 9/12] START C=10, penalty=elasticnet...................................\n",
      "[CV 4/5; 9/12] END ......C=10, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 5/5; 9/12] START C=10, penalty=elasticnet...................................\n",
      "[CV 5/5; 9/12] END ......C=10, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 1/5; 10/12] START C=100, penalty=l1.........................................\n",
      "[CV 1/5; 10/12] END ............C=100, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/5; 10/12] START C=100, penalty=l1.........................................\n",
      "[CV 2/5; 10/12] END ............C=100, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 3/5; 10/12] START C=100, penalty=l1.........................................\n",
      "[CV 3/5; 10/12] END ............C=100, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 4/5; 10/12] START C=100, penalty=l1.........................................\n",
      "[CV 4/5; 10/12] END ............C=100, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 5/5; 10/12] START C=100, penalty=l1.........................................\n",
      "[CV 5/5; 10/12] END ............C=100, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 1/5; 11/12] START C=100, penalty=l2.........................................\n",
      "[CV 1/5; 11/12] END ..........C=100, penalty=l2;, score=0.979 total time=   5.1s\n",
      "[CV 2/5; 11/12] START C=100, penalty=l2.........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 11/12] END ..........C=100, penalty=l2;, score=0.981 total time=   6.6s\n",
      "[CV 3/5; 11/12] START C=100, penalty=l2.........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 11/12] END ..........C=100, penalty=l2;, score=0.983 total time=   5.7s\n",
      "[CV 4/5; 11/12] START C=100, penalty=l2.........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 11/12] END ..........C=100, penalty=l2;, score=0.988 total time=   6.9s\n",
      "[CV 5/5; 11/12] START C=100, penalty=l2.........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 11/12] END ..........C=100, penalty=l2;, score=0.985 total time=   6.7s\n",
      "[CV 1/5; 12/12] START C=100, penalty=elasticnet.................................\n",
      "[CV 1/5; 12/12] END ....C=100, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 2/5; 12/12] START C=100, penalty=elasticnet.................................\n",
      "[CV 2/5; 12/12] END ....C=100, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 3/5; 12/12] START C=100, penalty=elasticnet.................................\n",
      "[CV 3/5; 12/12] END ....C=100, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 4/5; 12/12] START C=100, penalty=elasticnet.................................\n",
      "[CV 4/5; 12/12] END ....C=100, penalty=elasticnet;, score=nan total time=   0.1s\n",
      "[CV 5/5; 12/12] START C=100, penalty=elasticnet.................................\n",
      "[CV 5/5; 12/12] END ....C=100, penalty=elasticnet;, score=nan total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.98              nan        nan 0.98791667        nan\n",
      "        nan 0.98625           nan        nan 0.98333333        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid=[{'C': [0.1, 1, 10, 100],\n",
       "                          'penalty': ['l1', 'l2', 'elasticnet']}],\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvec_grid_search.fit(C_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l2'}\n",
      "0.9879166666666667\n",
      "LogisticRegression(C=1)\n"
     ]
    }
   ],
   "source": [
    "print(lvec_grid_search.best_params_)\n",
    "print(lvec_grid_search.best_score_)\n",
    "print(lvec_grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для модели логистической регрессии точность лучше у count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf_df\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "naivetf_grid_search = GridSearchCV(GaussianNB(),\n",
    "                               [{'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]}],\n",
    "                               cv=5,\n",
    "                               verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5; 1/4] START var_smoothing=1e-09.........................................\n",
      "[CV 1/5; 1/4] END ..........var_smoothing=1e-09;, score=0.952 total time=   1.7s\n",
      "[CV 2/5; 1/4] START var_smoothing=1e-09.........................................\n",
      "[CV 2/5; 1/4] END ..........var_smoothing=1e-09;, score=0.931 total time=   1.5s\n",
      "[CV 3/5; 1/4] START var_smoothing=1e-09.........................................\n",
      "[CV 3/5; 1/4] END ..........var_smoothing=1e-09;, score=0.940 total time=   1.6s\n",
      "[CV 4/5; 1/4] START var_smoothing=1e-09.........................................\n",
      "[CV 4/5; 1/4] END ..........var_smoothing=1e-09;, score=0.929 total time=   1.5s\n",
      "[CV 5/5; 1/4] START var_smoothing=1e-09.........................................\n",
      "[CV 5/5; 1/4] END ..........var_smoothing=1e-09;, score=0.948 total time=   1.5s\n",
      "[CV 1/5; 2/4] START var_smoothing=1e-08.........................................\n",
      "[CV 1/5; 2/4] END ..........var_smoothing=1e-08;, score=0.952 total time=   1.7s\n",
      "[CV 2/5; 2/4] START var_smoothing=1e-08.........................................\n",
      "[CV 2/5; 2/4] END ..........var_smoothing=1e-08;, score=0.931 total time=   1.5s\n",
      "[CV 3/5; 2/4] START var_smoothing=1e-08.........................................\n",
      "[CV 3/5; 2/4] END ..........var_smoothing=1e-08;, score=0.940 total time=   1.6s\n",
      "[CV 4/5; 2/4] START var_smoothing=1e-08.........................................\n",
      "[CV 4/5; 2/4] END ..........var_smoothing=1e-08;, score=0.929 total time=   1.5s\n",
      "[CV 5/5; 2/4] START var_smoothing=1e-08.........................................\n",
      "[CV 5/5; 2/4] END ..........var_smoothing=1e-08;, score=0.948 total time=   1.5s\n",
      "[CV 1/5; 3/4] START var_smoothing=1e-07.........................................\n",
      "[CV 1/5; 3/4] END ..........var_smoothing=1e-07;, score=0.954 total time=   1.6s\n",
      "[CV 2/5; 3/4] START var_smoothing=1e-07.........................................\n",
      "[CV 2/5; 3/4] END ..........var_smoothing=1e-07;, score=0.933 total time=   1.6s\n",
      "[CV 3/5; 3/4] START var_smoothing=1e-07.........................................\n",
      "[CV 3/5; 3/4] END ..........var_smoothing=1e-07;, score=0.948 total time=   1.7s\n",
      "[CV 4/5; 3/4] START var_smoothing=1e-07.........................................\n",
      "[CV 4/5; 3/4] END ..........var_smoothing=1e-07;, score=0.935 total time=   1.5s\n",
      "[CV 5/5; 3/4] START var_smoothing=1e-07.........................................\n",
      "[CV 5/5; 3/4] END ..........var_smoothing=1e-07;, score=0.950 total time=   1.6s\n",
      "[CV 1/5; 4/4] START var_smoothing=1e-06.........................................\n",
      "[CV 1/5; 4/4] END ..........var_smoothing=1e-06;, score=0.954 total time=   1.5s\n",
      "[CV 2/5; 4/4] START var_smoothing=1e-06.........................................\n",
      "[CV 2/5; 4/4] END ..........var_smoothing=1e-06;, score=0.935 total time=   1.5s\n",
      "[CV 3/5; 4/4] START var_smoothing=1e-06.........................................\n",
      "[CV 3/5; 4/4] END ..........var_smoothing=1e-06;, score=0.948 total time=   1.5s\n",
      "[CV 4/5; 4/4] START var_smoothing=1e-06.........................................\n",
      "[CV 4/5; 4/4] END ..........var_smoothing=1e-06;, score=0.944 total time=   1.6s\n",
      "[CV 5/5; 4/4] START var_smoothing=1e-06.........................................\n",
      "[CV 5/5; 4/4] END ..........var_smoothing=1e-06;, score=0.950 total time=   1.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GaussianNB(),\n",
       "             param_grid=[{'var_smoothing': [1e-09, 1e-08, 1e-07, 1e-06]}],\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naivetf_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 1e-06}\n",
      "0.94625\n",
      "GaussianNB(var_smoothing=1e-06)\n"
     ]
    }
   ],
   "source": [
    "print(naivetf_grid_search.best_params_)\n",
    "print(naivetf_grid_search.best_score_)\n",
    "print(naivetf_grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = count_df\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_train, C_test, y_train, y_test = train_test_split(C, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "naivevec_grid_search = GridSearchCV(GaussianNB(),\n",
    "                               [{'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]}],\n",
    "                               cv=5,\n",
    "                               verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5; 1/4] START var_smoothing=1e-09.........................................\n",
      "[CV 1/5; 1/4] END ..........var_smoothing=1e-09;, score=0.960 total time=   1.7s\n",
      "[CV 2/5; 1/4] START var_smoothing=1e-09.........................................\n",
      "[CV 2/5; 1/4] END ..........var_smoothing=1e-09;, score=0.931 total time=   1.7s\n",
      "[CV 3/5; 1/4] START var_smoothing=1e-09.........................................\n",
      "[CV 3/5; 1/4] END ..........var_smoothing=1e-09;, score=0.944 total time=   1.6s\n",
      "[CV 4/5; 1/4] START var_smoothing=1e-09.........................................\n",
      "[CV 4/5; 1/4] END ..........var_smoothing=1e-09;, score=0.921 total time=   1.7s\n",
      "[CV 5/5; 1/4] START var_smoothing=1e-09.........................................\n",
      "[CV 5/5; 1/4] END ..........var_smoothing=1e-09;, score=0.948 total time=   1.6s\n",
      "[CV 1/5; 2/4] START var_smoothing=1e-08.........................................\n",
      "[CV 1/5; 2/4] END ..........var_smoothing=1e-08;, score=0.960 total time=   1.6s\n",
      "[CV 2/5; 2/4] START var_smoothing=1e-08.........................................\n",
      "[CV 2/5; 2/4] END ..........var_smoothing=1e-08;, score=0.931 total time=   1.6s\n",
      "[CV 3/5; 2/4] START var_smoothing=1e-08.........................................\n",
      "[CV 3/5; 2/4] END ..........var_smoothing=1e-08;, score=0.944 total time=   1.6s\n",
      "[CV 4/5; 2/4] START var_smoothing=1e-08.........................................\n",
      "[CV 4/5; 2/4] END ..........var_smoothing=1e-08;, score=0.921 total time=   1.7s\n",
      "[CV 5/5; 2/4] START var_smoothing=1e-08.........................................\n",
      "[CV 5/5; 2/4] END ..........var_smoothing=1e-08;, score=0.948 total time=   1.6s\n",
      "[CV 1/5; 3/4] START var_smoothing=1e-07.........................................\n",
      "[CV 1/5; 3/4] END ..........var_smoothing=1e-07;, score=0.969 total time=   1.6s\n",
      "[CV 2/5; 3/4] START var_smoothing=1e-07.........................................\n",
      "[CV 2/5; 3/4] END ..........var_smoothing=1e-07;, score=0.935 total time=   1.6s\n",
      "[CV 3/5; 3/4] START var_smoothing=1e-07.........................................\n",
      "[CV 3/5; 3/4] END ..........var_smoothing=1e-07;, score=0.946 total time=   1.6s\n",
      "[CV 4/5; 3/4] START var_smoothing=1e-07.........................................\n",
      "[CV 4/5; 3/4] END ..........var_smoothing=1e-07;, score=0.929 total time=   1.7s\n",
      "[CV 5/5; 3/4] START var_smoothing=1e-07.........................................\n",
      "[CV 5/5; 3/4] END ..........var_smoothing=1e-07;, score=0.933 total time=   1.7s\n",
      "[CV 1/5; 4/4] START var_smoothing=1e-06.........................................\n",
      "[CV 1/5; 4/4] END ..........var_smoothing=1e-06;, score=0.973 total time=   1.6s\n",
      "[CV 2/5; 4/4] START var_smoothing=1e-06.........................................\n",
      "[CV 2/5; 4/4] END ..........var_smoothing=1e-06;, score=0.952 total time=   1.6s\n",
      "[CV 3/5; 4/4] START var_smoothing=1e-06.........................................\n",
      "[CV 3/5; 4/4] END ..........var_smoothing=1e-06;, score=0.981 total time=   1.6s\n",
      "[CV 4/5; 4/4] START var_smoothing=1e-06.........................................\n",
      "[CV 4/5; 4/4] END ..........var_smoothing=1e-06;, score=0.963 total time=   1.6s\n",
      "[CV 5/5; 4/4] START var_smoothing=1e-06.........................................\n",
      "[CV 5/5; 4/4] END ..........var_smoothing=1e-06;, score=0.840 total time=   1.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GaussianNB(),\n",
       "             param_grid=[{'var_smoothing': [1e-09, 1e-08, 1e-07, 1e-06]}],\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naivevec_grid_search.fit(C_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 1e-07}\n",
      "0.9425000000000001\n",
      "GaussianNB(var_smoothing=1e-07)\n"
     ]
    }
   ],
   "source": [
    "print(naivevec_grid_search.best_params_)\n",
    "print(naivevec_grid_search.best_score_)\n",
    "print(naivevec_grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате сравнения для Naive Bayes точность выше при TF - IDF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "935a784c055a7b21e047e8af34b03b2623f1270c39444abb64202b2d0bed73c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
